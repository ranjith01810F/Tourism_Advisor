{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerID  ProdTaken        Age  TypeofContact  CityTier  \\\n",
      "0         200000          1  41.000000              1         3   \n",
      "1         200001          0  49.000000              0         1   \n",
      "2         200002          1  37.000000              1         1   \n",
      "3         200003          0  33.000000              0         1   \n",
      "4         200004          0  37.622265              1         1   \n",
      "...          ...        ...        ...            ...       ...   \n",
      "4883      204883          1  49.000000              1         3   \n",
      "4884      204884          1  28.000000              0         1   \n",
      "4885      204885          1  52.000000              1         3   \n",
      "4886      204886          1  19.000000              1         3   \n",
      "4887      204887          1  36.000000              1         1   \n",
      "\n",
      "      DurationOfPitch  Occupation  Gender  NumberOfPersonVisiting  \\\n",
      "0                 6.0           2       0                       3   \n",
      "1                14.0           2       1                       3   \n",
      "2                 8.0           0       1                       3   \n",
      "3                 9.0           2       0                       2   \n",
      "4                 8.0           3       1                       2   \n",
      "...               ...         ...     ...                     ...   \n",
      "4883              9.0           3       1                       3   \n",
      "4884             31.0           2       1                       4   \n",
      "4885             17.0           2       0                       4   \n",
      "4886             16.0           3       1                       3   \n",
      "4887             14.0           2       1                       4   \n",
      "\n",
      "      NumberOfFollowups  ProductPitched  PreferredPropertyStar  MaritalStatus  \\\n",
      "0                   3.0               1                    3.0              2   \n",
      "1                   4.0               1                    4.0              0   \n",
      "2                   4.0               0                    3.0              2   \n",
      "3                   3.0               0                    3.0              0   \n",
      "4                   3.0               0                    4.0              0   \n",
      "...                 ...             ...                    ...            ...   \n",
      "4883                5.0               1                    4.0              3   \n",
      "4884                5.0               0                    3.0              2   \n",
      "4885                4.0               3                    4.0              1   \n",
      "4886                4.0               0                    3.0              2   \n",
      "4887                4.0               0                    4.0              3   \n",
      "\n",
      "      NumberOfTrips  Passport  PitchSatisfactionScore  OwnCar  \\\n",
      "0               1.0         1                       2       1   \n",
      "1               2.0         0                       3       1   \n",
      "2               7.0         1                       3       0   \n",
      "3               2.0         1                       5       1   \n",
      "4               1.0         0                       5       1   \n",
      "...             ...       ...                     ...     ...   \n",
      "4883            2.0         1                       1       1   \n",
      "4884            3.0         1                       3       1   \n",
      "4885            7.0         0                       1       1   \n",
      "4886            3.0         0                       5       0   \n",
      "4887            3.0         1                       3       1   \n",
      "\n",
      "      NumberOfChildrenVisiting  Designation  MonthlyIncome  \n",
      "0                          0.0            2        20993.0  \n",
      "1                          2.0            2        20130.0  \n",
      "2                          0.0            1        17090.0  \n",
      "3                          1.0            1        17909.0  \n",
      "4                          0.0            1        18468.0  \n",
      "...                        ...          ...            ...  \n",
      "4883                       1.0            2        26576.0  \n",
      "4884                       2.0            1        21212.0  \n",
      "4885                       3.0            3        31820.0  \n",
      "4886                       2.0            1        20289.0  \n",
      "4887                       2.0            1        24041.0  \n",
      "\n",
      "[4888 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding for categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df1['TypeofContact'] = label_encoder.fit_transform(df1['TypeofContact'])\n",
    "df1['Occupation'] = label_encoder.fit_transform(df1['Occupation'])\n",
    "df1['Gender'] = label_encoder.fit_transform(df1['Gender'])\n",
    "df1['ProductPitched'] = label_encoder.fit_transform(df1['ProductPitched'])\n",
    "df1['MaritalStatus'] = label_encoder.fit_transform(df1['MaritalStatus'])\n",
    "df1['Designation'] = label_encoder.fit_transform(df1['Designation'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: ['Age' 'CustomerID' 'MonthlyIncome' 'DurationOfPitch' 'Passport'\n",
      " 'NumberOfTrips' 'PitchSatisfactionScore' 'MaritalStatus'\n",
      " 'NumberOfFollowups' 'ProductPitched']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "    \n",
    "# Define the features and target variable\n",
    "X = df1.drop(columns=['ProdTaken'])\n",
    "y = df1['ProdTaken']\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top 10 features\n",
    "top_features_rf = feature_importances.head(10)['Feature'].values\n",
    "\n",
    "# Print top features\n",
    "print(\"Top 10 features:\", top_features_rf)\n",
    "\n",
    "# Update the feature set with the selected top features\n",
    "X_selected_rf = X[top_features_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_common: (3910, 10)\n",
      "Shape of X_test_common: (978, 10)\n",
      "Shape of y_train: (3910,)\n",
      "Shape of y_test: (978,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets using the common features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_rf, y, test_size=0.2, random_state=42)\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Shape of X_train_common:\", X_train.shape)\n",
    "print(\"Shape of X_test_common:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_smote: (6362, 10)\n",
      "Shape of y_train_smote: (6362,)\n",
      "Value counts for y_train_smote:\n",
      "ProdTaken\n",
      "0    3181\n",
      "1    3181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the shapes of the new training sets\n",
    "print(\"Shape of X_train_smote:\", X_train_smote.shape)\n",
    "print(\"Shape of y_train_smote:\", y_train_smote.shape)\n",
    "\n",
    "# Check the value counts after SMote\n",
    "print(\"Value counts for y_train_smote:\")\n",
    "print(y_train_smote.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled: (6362, 10)\n",
      "Shape of X_test_scaled: (978, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "\n",
    "# Transform the testing data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Print the shapes of the scaled training and testing sets\n",
    "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Shape of X_test_scaled:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Accuracy: 0.6351776171015404\n",
      "Naive Bayes Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59      3181\n",
      "           1       0.61      0.74      0.67      3181\n",
      "\n",
      "    accuracy                           0.64      6362\n",
      "   macro avg       0.64      0.64      0.63      6362\n",
      "weighted avg       0.64      0.64      0.63      6362\n",
      "\n",
      "Naive Bayes Testing Accuracy: 0.5613496932515337\n",
      "Naive Bayes Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.52      0.66       787\n",
      "           1       0.27      0.71      0.39       191\n",
      "\n",
      "    accuracy                           0.56       978\n",
      "   macro avg       0.57      0.62      0.52       978\n",
      "weighted avg       0.76      0.56      0.61       978\n",
      "\n",
      "Naive Bayes Testing Confusion Matrix:\n",
      "[[413 374]\n",
      " [ 55 136]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_nb = nb_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_nb = nb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_nb = accuracy_score(y_train_smote, y_train_pred_nb)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_nb = accuracy_score(y_test, y_test_pred_nb)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_nb = classification_report(y_train_smote, y_train_pred_nb)\n",
    "report_test_nb = classification_report(y_test, y_test_pred_nb)\n",
    "\n",
    "# Print results\n",
    "print(f\"Naive Bayes Training Accuracy: {accuracy_train_nb}\")\n",
    "print(\"Naive Bayes Training Classification Report:\")\n",
    "print(report_train_nb)\n",
    "\n",
    "print(f\"Naive Bayes Testing Accuracy: {accuracy_test_nb}\")\n",
    "print(\"Naive Bayes Testing Classification Report:\")\n",
    "print(report_test_nb)\n",
    "\n",
    "print(\"Naive Bayes Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned Model (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'var_smoothing': 1e-09}\n",
      "Naive Bayes Training Accuracy: 0.6351776171015404\n",
      "Naive Bayes Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59      3181\n",
      "           1       0.61      0.74      0.67      3181\n",
      "\n",
      "    accuracy                           0.64      6362\n",
      "   macro avg       0.64      0.64      0.63      6362\n",
      "weighted avg       0.64      0.64      0.63      6362\n",
      "\n",
      "Naive Bayes Testing Accuracy: 0.5613496932515337\n",
      "Naive Bayes Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.52      0.66       787\n",
      "           1       0.27      0.71      0.39       191\n",
      "\n",
      "    accuracy                           0.56       978\n",
      "   macro avg       0.57      0.62      0.52       978\n",
      "weighted avg       0.76      0.56      0.61       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=nb_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_nb_clf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Train the best estimator\n",
    "best_nb_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_nb = best_nb_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_nb = best_nb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_at_nb = accuracy_score(y_train_smote, y_train_pred_nb)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_at_nb = accuracy_score(y_test, y_test_pred_nb)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_at_nb = classification_report(y_train_smote, y_train_pred_nb)\n",
    "report_test_at_nb = classification_report(y_test, y_test_pred_nb)\n",
    "\n",
    "# Print results\n",
    "print(f\"Naive Bayes Training Accuracy: {accuracy_train_at_nb}\")\n",
    "print(\"Naive Bayes Training Classification Report:\")\n",
    "print(report_train_at_nb)\n",
    "\n",
    "print(f\"Naive Bayes Testing Accuracy: {accuracy_test_at_nb}\")\n",
    "print(\"Naive Bayes Testing Classification Report:\")\n",
    "print(report_test_at_nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Training Accuracy: 0.8992455202766426\n",
      "GBM Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      3181\n",
      "           1       0.94      0.86      0.89      3181\n",
      "\n",
      "    accuracy                           0.90      6362\n",
      "   macro avg       0.90      0.90      0.90      6362\n",
      "weighted avg       0.90      0.90      0.90      6362\n",
      "\n",
      "GBM Testing Accuracy: 0.8374233128834356\n",
      "GBM Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       787\n",
      "           1       0.60      0.51      0.55       191\n",
      "\n",
      "    accuracy                           0.84       978\n",
      "   macro avg       0.74      0.71      0.73       978\n",
      "weighted avg       0.83      0.84      0.83       978\n",
      "\n",
      "GBM Testing Confusion Matrix:\n",
      "[[721  66]\n",
      " [ 93  98]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the GBM classifier\n",
    "gbm_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the classifier on the SMOTE variables\n",
    "gbm_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_gbm = gbm_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_gbm = gbm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_gbm = accuracy_score(y_train_smote, y_train_pred_gbm)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_gbm = accuracy_score(y_test, y_test_pred_gbm)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_gbm = classification_report(y_train_smote, y_train_pred_gbm)\n",
    "report_test_gbm = classification_report(y_test, y_test_pred_gbm)\n",
    "\n",
    "# Print results\n",
    "print(f\"GBM Training Accuracy: {accuracy_train_gbm}\")\n",
    "print(\"GBM Training Classification Report:\")\n",
    "print(report_train_gbm)\n",
    "\n",
    "print(f\"GBM Testing Accuracy: {accuracy_test_gbm}\")\n",
    "print(\"GBM Testing Classification Report:\")\n",
    "print(report_test_gbm)\n",
    "\n",
    "print(\"GBM Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_gbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunded Model(GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'learning_rate': 0.2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 300, 'subsample': 0.8}\n",
      "GBM Training Accuracy: 0.9992140836215027\n",
      "GBM Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3181\n",
      "           1       1.00      1.00      1.00      3181\n",
      "\n",
      "    accuracy                           1.00      6362\n",
      "   macro avg       1.00      1.00      1.00      6362\n",
      "weighted avg       1.00      1.00      1.00      6362\n",
      "\n",
      "GBM Testing Accuracy: 0.8895705521472392\n",
      "GBM Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       787\n",
      "           1       0.81      0.57      0.67       191\n",
      "\n",
      "    accuracy                           0.89       978\n",
      "   macro avg       0.86      0.77      0.80       978\n",
      "weighted avg       0.88      0.89      0.88       978\n",
      "\n",
      "GBM Testing Confusion Matrix:\n",
      "[[761  26]\n",
      " [ 82 109]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the GBM classifier with default parameters\n",
    "gbm_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gbm_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "gbm_clf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "best_gbm_clf = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Train the best estimator\n",
    "best_gbm_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_gbm = best_gbm_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_gbm = best_gbm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_at_gbm = accuracy_score(y_train_smote, y_train_pred_gbm)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_at_gbm = accuracy_score(y_test, y_test_pred_gbm)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_at_gbm = classification_report(y_train_smote, y_train_pred_gbm)\n",
    "report_test_at_gbm = classification_report(y_test, y_test_pred_gbm)\n",
    "\n",
    "# Print results\n",
    "print(f\"GBM Training Accuracy: {accuracy_train_at_gbm}\")\n",
    "print(\"GBM Training Classification Report:\")\n",
    "print(report_train_at_gbm)\n",
    "\n",
    "print(f\"GBM Testing Accuracy: {accuracy_test_at_gbm}\")\n",
    "print(\"GBM Testing Classification Report:\")\n",
    "print(report_test_at_gbm)\n",
    "\n",
    "print(\"GBM Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_gbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3181\n",
      "           1       1.00      1.00      1.00      3181\n",
      "\n",
      "    accuracy                           1.00      6362\n",
      "   macro avg       1.00      1.00      1.00      6362\n",
      "weighted avg       1.00      1.00      1.00      6362\n",
      "\n",
      "Random Forest Testing Accuracy: 0.878323108384458\n",
      "Random Forest Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       787\n",
      "           1       0.74      0.58      0.65       191\n",
      "\n",
      "    accuracy                           0.88       978\n",
      "   macro avg       0.82      0.77      0.79       978\n",
      "weighted avg       0.87      0.88      0.87       978\n",
      "\n",
      "Random Forest Testing Confusion Matrix:\n",
      "[[748  39]\n",
      " [ 80 111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the SMOTE variables\n",
    "rf_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_rf = rf_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_rf = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_rf = accuracy_score(y_train_smote, y_train_pred_rf)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_rf = classification_report(y_train_smote, y_train_pred_rf)\n",
    "report_test_rf = classification_report(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print results\n",
    "print(f\"Random Forest Training Accuracy: {accuracy_train_rf}\")\n",
    "print(\"Random Forest Training Classification Report:\")\n",
    "print(report_train_rf)\n",
    "\n",
    "print(f\"Random Forest Testing Accuracy: {accuracy_test_rf}\")\n",
    "print(\"Random Forest Testing Classification Report:\")\n",
    "print(report_test_rf)\n",
    "\n",
    "print(\"Random Forest Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned model (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters found: {'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3181\n",
      "           1       1.00      1.00      1.00      3181\n",
      "\n",
      "    accuracy                           1.00      6362\n",
      "   macro avg       1.00      1.00      1.00      6362\n",
      "weighted avg       1.00      1.00      1.00      6362\n",
      "\n",
      "Random Forest Testing Accuracy: 0.8926380368098159\n",
      "Random Forest Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       787\n",
      "           1       0.78      0.63      0.70       191\n",
      "\n",
      "    accuracy                           0.89       978\n",
      "   macro avg       0.85      0.79      0.82       978\n",
      "weighted avg       0.89      0.89      0.89       978\n",
      "\n",
      "Random Forest Testing Confusion Matrix:\n",
      "[[753  34]\n",
      " [ 71 120]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Train the best estimator\n",
    "best_rf_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_at_pred_rf = best_rf_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_at_pred_rf = best_rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_at_rf = accuracy_score(y_train_smote, y_train_at_pred_rf)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_at_rf = accuracy_score(y_test, y_test_at_pred_rf)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_at_rf = classification_report(y_train_smote, y_train_at_pred_rf)\n",
    "report_test_at_rf = classification_report(y_test, y_test_at_pred_rf)\n",
    "\n",
    "# Print results\n",
    "print(f\"Random Forest Training Accuracy: {accuracy_train_at_rf}\")\n",
    "print(\"Random Forest Training Classification Report:\")\n",
    "print(report_train_at_rf)\n",
    "\n",
    "print(f\"Random Forest Testing Accuracy: {accuracy_test_at_rf}\")\n",
    "print(\"Random Forest Testing Classification Report:\")\n",
    "print(report_test_at_rf)\n",
    "\n",
    "print(\"Random Forest Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_at_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN) Training Accuracy: 0.872052813580635\n",
      "K-Nearest Neighbors (KNN) Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3181\n",
      "           1       0.84      0.92      0.88      3181\n",
      "\n",
      "    accuracy                           0.87      6362\n",
      "   macro avg       0.87      0.87      0.87      6362\n",
      "weighted avg       0.87      0.87      0.87      6362\n",
      "\n",
      "K-Nearest Neighbors (KNN) Testing Accuracy: 0.7372188139059305\n",
      "K-Nearest Neighbors (KNN) Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       787\n",
      "           1       0.40      0.70      0.51       191\n",
      "\n",
      "    accuracy                           0.74       978\n",
      "   macro avg       0.66      0.72      0.67       978\n",
      "weighted avg       0.81      0.74      0.76       978\n",
      "\n",
      "K-Nearest Neighbors (KNN) Testing Confusion Matrix:\n",
      "[[587 200]\n",
      " [ 57 134]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
    "\n",
    "# Train the classifier on the SMOTE variables\n",
    "knn_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_knn = knn_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_pred_knn = knn_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_knn = accuracy_score(y_train_smote, y_train_pred_knn)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_knn = classification_report(y_train_smote, y_train_pred_knn)\n",
    "report_test_knn = classification_report(y_test, y_test_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"K-Nearest Neighbors (KNN) Training Accuracy: {accuracy_train_knn}\")\n",
    "print(\"K-Nearest Neighbors (KNN) Training Classification Report:\")\n",
    "print(report_train_knn)\n",
    "\n",
    "print(f\"K-Nearest Neighbors (KNN) Testing Accuracy: {accuracy_test_knn}\")\n",
    "print(\"K-Nearest Neighbors (KNN) Testing Classification Report:\")\n",
    "print(report_test_knn)\n",
    "\n",
    "print(\"K-Nearest Neighbors (KNN) Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters found: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "K-Nearest Neighbors (KNN) Training Accuracy: 1.0\n",
      "K-Nearest Neighbors (KNN) Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3181\n",
      "           1       1.00      1.00      1.00      3181\n",
      "\n",
      "    accuracy                           1.00      6362\n",
      "   macro avg       1.00      1.00      1.00      6362\n",
      "weighted avg       1.00      1.00      1.00      6362\n",
      "\n",
      "K-Nearest Neighbors (KNN) Testing Accuracy: 0.7822085889570553\n",
      "K-Nearest Neighbors (KNN) Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       787\n",
      "           1       0.46      0.65      0.54       191\n",
      "\n",
      "    accuracy                           0.78       978\n",
      "   macro avg       0.68      0.73      0.70       978\n",
      "weighted avg       0.82      0.78      0.80       978\n",
      "\n",
      "K-Nearest Neighbors (KNN) Testing Confusion Matrix:\n",
      "[[640 147]\n",
      " [ 66 125]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_knn_clf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Train the best estimator\n",
    "best_knn_clf.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_at_pred_knn = best_knn_clf.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_test_at_pred_knn = best_knn_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "accuracy_train_at_knn = accuracy_score(y_train_smote, y_train_at_pred_knn)\n",
    "\n",
    "# Evaluate the classifier on the testing set\n",
    "accuracy_test_at_knn = accuracy_score(y_test, y_test_at_pred_knn)\n",
    "\n",
    "# Generate classification reports\n",
    "report_train_at_knn = classification_report(y_train_smote, y_train_at_pred_knn)\n",
    "report_test_at_knn = classification_report(y_test, y_test_at_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"K-Nearest Neighbors (KNN) Training Accuracy: {accuracy_train_at_knn}\")\n",
    "print(\"K-Nearest Neighbors (KNN) Training Classification Report:\")\n",
    "print(report_train_at_knn)\n",
    "\n",
    "print(f\"K-Nearest Neighbors (KNN) Testing Accuracy: {accuracy_test_at_knn}\")\n",
    "print(\"K-Nearest Neighbors (KNN) Testing Classification Report:\")\n",
    "print(report_test_at_knn)\n",
    "\n",
    "print(\"K-Nearest Neighbors (KNN) Testing Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_at_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracies Before Tuning:\n",
      "Naive Bayes: 0.5613496932515337\n",
      "Gradient Boosting: 0.8374233128834356\n",
      "Random Forest: 0.878323108384458\n",
      "K-Nearest Neighbors: 0.7822085889570553\n",
      "\n",
      "Test Accuracies After Tuning:\n",
      "Naive Bayes: 0.5613496932515337\n",
      "Gradient Boosting: 0.8374233128834356\n",
      "Random Forest: 0.878323108384458\n",
      "K-Nearest Neighbors: 0.7822085889570553\n",
      "\n",
      "The classifier with the maximum accuracy after tuning is: Random Forest with accuracy: 0.878323108384458\n"
     ]
    }
   ],
   "source": [
    "# Test accuracies before tuning\n",
    "accuracy_test_before_tuning = {\n",
    "    'Naive Bayes': accuracy_score(y_test, y_test_pred_nb),\n",
    "    'Gradient Boosting': accuracy_score(y_test, y_test_pred_gbm),\n",
    "    'Random Forest': accuracy_score(y_test, y_test_pred_rf),\n",
    "    'K-Nearest Neighbors': accuracy_score(y_test, y_test_pred_knn)\n",
    "}\n",
    "\n",
    "# Test accuracies after tuning\n",
    "accuracy_test_after_tuning = {\n",
    "    'Naive Bayes': accuracy_score(y_test, y_test_pred_nb),\n",
    "    'Gradient Boosting': accuracy_score(y_test, y_test_pred_gbm),\n",
    "    'Random Forest': accuracy_score(y_test, y_test_pred_rf),\n",
    "    'K-Nearest Neighbors': accuracy_score(y_test, y_test_at_pred_knn)\n",
    "}\n",
    "\n",
    "# Print test accuracies\n",
    "print(\"Test Accuracies Before Tuning:\")\n",
    "for clf, accuracy in accuracy_test_before_tuning.items():\n",
    "    print(f\"{clf}: {accuracy}\")\n",
    "\n",
    "print(\"\\nTest Accuracies After Tuning:\")\n",
    "for clf, accuracy in accuracy_test_after_tuning.items():\n",
    "    print(f\"{clf}: {accuracy}\")\n",
    "\n",
    "# Find the classifier with the maximum accuracy after tuning\n",
    "max_accuracy_clf = max(accuracy_test_after_tuning, key=accuracy_test_after_tuning.get)\n",
    "max_accuracy = accuracy_test_after_tuning[max_accuracy_clf]\n",
    "\n",
    "print(f\"\\nThe classifier with the maximum accuracy after tuning is: {max_accuracy_clf} with accuracy: {max_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "indianred"
         },
         "name": "Before Tuning - Training Accuracy",
         "type": "bar",
         "x": [
          "Naive Bayes",
          "Gradient Boosting",
          "Random Forest",
          "KNN"
         ],
         "y": [
          0.6351776171015404,
          0.9992140836215027,
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "lightsalmon"
         },
         "name": "Before Tuning - Testing Accuracy",
         "type": "bar",
         "x": [
          "Naive Bayes",
          "Gradient Boosting",
          "Random Forest",
          "KNN"
         ],
         "y": [
          0.5613496932515337,
          0.8895705521472392,
          0.8926380368098159,
          0.7822085889570553
         ]
        },
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "After Tuning - Training Accuracy",
         "type": "bar",
         "x": [
          "Naive Bayes",
          "Gradient Boosting",
          "Random Forest",
          "KNN"
         ],
         "y": [
          0.6351776171015404,
          0.9992140836215027,
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "skyblue"
         },
         "name": "After Tuning - Testing Accuracy",
         "type": "bar",
         "x": [
          "Naive Bayes",
          "Gradient Boosting",
          "Random Forest",
          "KNN"
         ],
         "y": [
          0.5613496932515337,
          0.8895705521472392,
          0.8926380368098159,
          0.7822085889570553
         ]
        }
       ],
       "layout": {
        "bargap": 0.15,
        "bargroupgap": 0.1,
        "barmode": "group",
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 0)",
         "bordercolor": "rgba(255, 255, 255, 0)",
         "x": 0,
         "y": 1
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Classifier Performance Before and After Tuning"
        },
        "xaxis": {
         "tickfont": {
          "size": 14
         }
        },
        "yaxis": {
         "tickfont": {
          "size": 14
         },
         "title": {
          "font": {
           "size": 16
          },
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define classifier names\n",
    "classifiers = ['Naive Bayes', 'Gradient Boosting', 'Random Forest', 'KNN']\n",
    "\n",
    "# Define training and testing accuracies before tuning\n",
    "accuracy_train_before_tuning = [accuracy_train_at_nb, accuracy_train_at_gbm, accuracy_train_at_rf, accuracy_train_at_knn]\n",
    "accuracy_test_before_tuning = [accuracy_test_at_nb, accuracy_test_at_gbm, accuracy_test_at_rf, accuracy_test_at_knn]\n",
    "\n",
    "# Define training and testing accuracies after tuning\n",
    "accuracy_train_after_tuning = [best_nb_clf.score(X_train_scaled, y_train_smote),\n",
    "                               best_gbm_clf.score(X_train_scaled, y_train_smote),\n",
    "                               best_rf_clf.score(X_train_scaled, y_train_smote),\n",
    "                               best_knn_clf.score(X_train_scaled, y_train_smote)]\n",
    "\n",
    "accuracy_test_after_tuning = [best_nb_clf.score(X_test_scaled, y_test),\n",
    "                              best_gbm_clf.score(X_test_scaled, y_test),\n",
    "                              best_rf_clf.score(X_test_scaled, y_test),\n",
    "                              best_knn_clf.score(X_test_scaled, y_test)]\n",
    "\n",
    "# Create traces for before and after tuning\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=classifiers,\n",
    "    y=accuracy_train_before_tuning,\n",
    "    name='Before Tuning - Training Accuracy',\n",
    "    marker_color='indianred'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=classifiers,\n",
    "    y=accuracy_test_before_tuning,\n",
    "    name='Before Tuning - Testing Accuracy',\n",
    "    marker_color='lightsalmon'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=classifiers,\n",
    "    y=accuracy_train_after_tuning,\n",
    "    name='After Tuning - Training Accuracy',\n",
    "    marker_color='lightblue'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=classifiers,\n",
    "    y=accuracy_test_after_tuning,\n",
    "    name='After Tuning - Testing Accuracy',\n",
    "    marker_color='skyblue'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Classifier Performance Before and After Tuning',\n",
    "    xaxis_tickfont_size=14,\n",
    "    yaxis=dict(\n",
    "        title='Accuracy',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)'\n",
    "    ),\n",
    "    barmode='group',\n",
    "    bargap=0.15,\n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
